{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlFdxD3pC69rKZ7RZmBDr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stkao05/vae/blob/main/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm binarized_mnist.npz\n",
        "!wget https://github.com/mgermain/MADE/releases/download/ICML2015/binarized_mnist.npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbwbHyjuMasd",
        "outputId": "9f01e4d2-4ce4-4898-c2b2-b5aa7f98a4a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'binarized_mnist.npz': No such file or directory\n",
            "--2024-06-19 06:31:50--  https://github.com/mgermain/MADE/releases/download/ICML2015/binarized_mnist.npz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/35685802/163f3f6a-fd86-11e4-8d0e-d7d2496d3296?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240619T063150Z&X-Amz-Expires=300&X-Amz-Signature=0ed75e7f32587e1eaa3bfc1c5dc1535bad101601bb107cd1de9011aa8619fd93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=35685802&response-content-disposition=attachment%3B%20filename%3Dbinarized_mnist.npz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-06-19 06:31:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/35685802/163f3f6a-fd86-11e4-8d0e-d7d2496d3296?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240619T063150Z&X-Amz-Expires=300&X-Amz-Signature=0ed75e7f32587e1eaa3bfc1c5dc1535bad101601bb107cd1de9011aa8619fd93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=35685802&response-content-disposition=attachment%3B%20filename%3Dbinarized_mnist.npz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219521332 (209M) [application/octet-stream]\n",
            "Saving to: ‘binarized_mnist.npz’\n",
            "\n",
            "binarized_mnist.npz 100%[===================>] 209.35M   146MB/s    in 1.4s    \n",
            "\n",
            "2024-06-19 06:31:52 (146 MB/s) - ‘binarized_mnist.npz’ saved [219521332/219521332]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH04uBE2MPI7",
        "outputId": "c2ec15a8-5907-4546-e667-b65af12d41c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-37de0423b637>:23: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
            "  train_ds = MINST(torch.from_numpy(f[\"train_data\"]).view(-1, 1, 28, 28).float())\n",
            "<ipython-input-12-37de0423b637>:24: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
            "  valid_ds = MINST(torch.from_numpy(f[\"valid_data\"]).view(-1, 1, 28, 28).float())\n",
            "<ipython-input-12-37de0423b637>:25: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
            "  test_ds = MINST(torch.from_numpy(f[\"test_data\"]).view(-1, 1, 28, 28).float())\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "class MINST(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "# f is a dict that contains: 'inputsize', 'valid_length', 'train_length', 'test_data', 'test_length', 'train_data', 'valid_data'\n",
        "with np.load('binarized_mnist.npz') as f:\n",
        "  train_ds = MINST(torch.from_numpy(f[\"train_data\"]).view(-1, 1, 28, 28).float())\n",
        "  valid_ds = MINST(torch.from_numpy(f[\"valid_data\"]).view(-1, 1, 28, 28).float())\n",
        "  test_ds = MINST(torch.from_numpy(f[\"test_data\"]).view(-1, 1, 28, 28).float())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), *self.shape)\n",
        "\n",
        "\n",
        "x = train_ds[0:8] # (1, 28, 28)\n",
        "\n",
        "encoder = nn.Sequential(\n",
        "  nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), # (28)\n",
        "  nn.ReLU(),\n",
        "  nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # (14)\n",
        "  nn.ReLU(),\n",
        "  nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # (7)\n",
        "  nn.ReLU(), # (64, 7, 7)\n",
        "  nn.Flatten(),\n",
        ")\n",
        "\n",
        "latent_dim = 2\n",
        "mean_fn = nn.Linear(64*7*7, latent_dim)\n",
        "logvar_fn = nn.Linear(64*7*7, latent_dim)\n",
        "\n",
        "decoder = nn.Sequential(\n",
        "  nn.Linear(latent_dim, 64*7*7),\n",
        "  Reshape(64, 7, 7), # (C, H, W)\n",
        "  nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "  nn.ReLU(),\n",
        "  nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
        "  nn.ReLU(),\n",
        "  nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
        "  nn.Sigmoid()\n",
        ")\n",
        "\n",
        "def forward(x):\n",
        "  h = encoder(x)\n",
        "\n",
        "  # reparameterization\n",
        "  z_mean = mean_fn(h)\n",
        "  z_logvar = logvar_fn(h)\n",
        "  z = z_mean + torch.exp(z_logvar) * torch.randn_like(z_mean) # (N, 2)\n",
        "  xh = decoder(z)\n",
        "\n",
        "  kld = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
        "  loss = F.binary_cross_entropy(xh, x) + kld\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "params = list(encoder.parameters()) + list(decoder.parameters())\n",
        "optimizer = torch.optim.Adam(params)\n",
        "\n",
        "for i in range(1000):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss = forward(x)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94WKtMIUMe8J",
        "outputId": "7971f4cc-f7f8-46e2-caff-1d6d82a8c131"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6626262664794922\n",
            "0.2908857762813568\n",
            "0.27100422978401184\n",
            "0.2624686658382416\n",
            "0.26304543018341064\n",
            "0.2569359242916107\n",
            "0.2620197534561157\n",
            "0.27027222514152527\n",
            "0.2691047787666321\n",
            "0.2627357542514801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLac4y4JTNoB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}